#!/bin/bash

# ICON
#
# ------------------------------------------
# Copyright (C) 2004-2024, DWD, MPI-M, DKRZ, KIT, ETH, MeteoSwiss
# Contact information: icon-model.org
# See AUTHORS.TXT for a list of authors
# See LICENSES/ for license information
# SPDX-License-Identifier: BSD-3-Clause
# ------------------------------------------

############################################################################
###                  Configure wrapper for JUWELS                        ###
###                           MSA-setup                                  ###
############################################################################

set -eu

# clear all modules and load Stage and modules for all dependencies
MODULES='Stages/2023 NVHPC/23.1 ParaStationMPI/5.8.0-1 netCDF-Fortran ecCodes libfyaml CMake'
BUILD_ENV="module --force purge; export USERINSTALLATIONS=/p/usersoftware/slmet/easybuild/stages/2023/; module load ${MODULES}; module list};"

SCRIPT_DIR=$(cd "$(dirname "$0")"; pwd)
ICON_DIR=$(cd "${SCRIPT_DIR}/../.."; pwd)

### Libraries
ROOT_ECCODES=/p/software/juwels/stages/2023/software/ecCodes/2.27.0-npsmpic-2022a
ROOT_GCCCORE=/p/software/juwels/stages/2023/software/GCCcore/11.3.0
ROOT_HDF5=/p/software/juwels/stages/2023/software/HDF5/1.12.2-npsmpic-2022a
ROOT_LIBFYAML=/p/usersoftware/slmet/easybuild/stages/2023/easybuild/juwels/software/libfyaml/0.8-GCCcore-11.3.0
ROOT_LIBXML2=/p/software/juwels/stages/2023/software/libxml2/2.9.13-GCCcore-11.3.0
ROOT_NETCDF=/p/software/juwels/stages/2023/software/netCDF/4.9.0-npsmpic-2022a
ROOT_NETCDFMINFORTRAN=/p/software/juwels/stages/2023/software/netCDF-Fortran/4.6.0-npsmpic-2022a
ROOT_NVHPC=/p/software/juwels/stages/2023/software/NVHPC/23.1
ROOT_NVIDIA_DRIVER=/p/software/juwels/stages/2023/software/nvidia-driver/default
ROOT_PNETCDF=/p/software/juwels/stages/2023/software/PnetCDF/1.12.3-npsmpic-2022a
ROOT_PSMPI=/p/software/juwels/stages/2023/software/psmpi/5.8.0-1-NVHPC-23.1

ECCODES_LIBS='-leccodes'
HDF5_LIBS='-lhdf5'
NETCDFF_LIBS='-lnetcdff'
NETCDF_LIBS='-lnetcdf'
PNETCDF_LIBS='-lpnetcdf'
XML2_LIBS='-lxml2'
FYAML_LIBS='-lfyaml'
BLAS_LAPACK_LIBS='-llapack -lblas -fortranlibs '

# Linking to libstc++ is required when using nvfortran + CUDA
STDCPP_LIBS='-lstdc++'

################################################################################

CC="${ROOT_PSMPI}/bin/mpicc"
CFLAGS='-g -O2'  #remove g and check if this has impact on performance, + testing
CPPFLAGS="-I${ROOT_ECCODES}/include -I${ROOT_HDF5}/include -I${ROOT_NETCDF}/include -I${ROOT_LIBXML2}/include/libxml2 -I${ROOT_LIBFYAML}/include"

FC="${ROOT_PSMPI}/bin/mpif90"
FCFLAGS="-I${ROOT_NETCDFMINFORTRAN}/include -g -O2 -Mrecursive -Mallocatable=03 -Minfo=accel,inline -Mstack_arrays" 
LDFLAGS="-L${ROOT_ECCODES}/lib64 -L${ROOT_ECCODES}/lib -L${ROOT_HDF5}/lib -L${ROOT_PNETCDF}/lib -L${ROOT_NETCDF}/lib -L${ROOT_NETCDFMINFORTRAN}/lib -L${ROOT_LIBXML2}/lib64 -L${ROOT_LIBFYAML}/lib -L${ROOT_GCCCORE}/lib64"

LIBS="-Wl,--as-needed ${XML2_LIBS} ${BLAS_LAPACK_LIBS} ${NETCDFF_LIBS} ${NETCDF_LIBS} ${PNETCDF_LIBS} ${HDF5_LIBS} ${ECCODES_LIBS} ${STDCPP_LIBS} ${FYAML_LIBS}"

CUDACXX=''
CUDAFLAGS='' ##check settings if alredy deprecated

# We use srun for MPI launche, for which a active project is needed. So disable MPI checks
MPI_LAUNCH=false
# --enable-gpu implies --disable-loop-exchange
# --enable-gpu already implies --enable-dim-swap (-D__USE_G2G and -D__SWAPDIM); rte-rrtmgp enabled per default
EXTRA_CONFIG_ARGS='--enable-coupling --enable-grib2 --enable-cdi-pio --enable-delayed-config'

# Speed up the configuration by disabling MPI checks:
EXTRA_CONFIG_ARGS+=' --disable-mpi-checks '

# Workaround for YAC on NVHPC 23.1
ICON_YAC_CFLAGS='-fortranlibs'
EXTRA_CONFIG_ARGS+=' yac_cv_fc_is_contiguous_works=yes'
ICON_YAC_FCFLAGS="-D'is_contiguous(arg)=.TRUE.'"

################################################################################

"${ICON_DIR}/configure" \
BUILD_ENV="$BUILD_ENV" \
CC="$CC" \
CFLAGS="$CFLAGS" \
CPPFLAGS="$CPPFLAGS" \
FC="$FC" \
FCFLAGS="$FCFLAGS" \
LDFLAGS="$LDFLAGS" \
ICON_YAC_CFLAGS="$ICON_YAC_CFLAGS" \
ICON_YAC_FCFLAGS="$ICON_YAC_FCFLAGS" \
LIBS="$LIBS" \
MPI_LAUNCH="$MPI_LAUNCH" \
CUDACXX="$CUDACXX" \
CUDAFLAGS="$CUDAFLAGS" \
${EXTRA_CONFIG_ARGS} \
"$@"

for arg in "$@"; do
  case $arg in
    -help | --help | --hel | --he | -h | -help=r* | --help=r* | --hel=r* | --he=r* | -hr* | -help=s* | --help=s* | --hel=s* | --he=s* | -hs*)
      test -n "${EXTRA_CONFIG_ARGS}" && echo '' && echo "This wrapper script ('$0') calls the configure script with the following extra arguments, which might override the default values listed above: ${EXTRA_CONFIG_ARGS}"
      exit 0 ;;
  esac
done

# Copy runscript-related files when building out-of-source:
if test $(pwd) != $(cd "${ICON_DIR}"; pwd); then
  echo "Copying runscript input files from the source directory..."
  rsync -uavz ${ICON_DIR}/run . --exclude='*.in' --exclude='.*' --exclude='standard_*' --exclude='*.log'
  ln -sf -t run/ ${ICON_DIR}/run/standard_*
  rsync -uavz ${ICON_DIR}/externals . --exclude='.git' --exclude='*.f90' --exclude='*.F90' --exclude='*.c' --exclude='*.h' --exclude='*.Po' --exclude='tests' --exclude='rrtmgp*.nc' --exclude='*.mod' --exclude='*.o'
  rsync -uavz ${ICON_DIR}/make_runscripts .
  rsync -uavz ${ICON_DIR}/scripts .
  ln -sf ${ICON_DIR}/data
  ln -sf ${ICON_DIR}/utils
  ln -sf ${ICON_DIR}/vertical_coord_tables
fi

#! /bin/bash
#SBATCH --job-name='exp.NextGEMS_R2B4_jsc.run'
#SBATCH --output=LOG.exp.NextGEMS_R2B4_jsc.run.run.o
#SBATCH --partition=develbooster
#SBATCH --constraint=gpu
#SBATCH --gres=gpu:4
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=48   # number of MPI tasks / node
#SBATCH --cpus-per-task=1      # number of OpenMP threads / MPI task (1 == no OpennMP, eg. on GPUs)
#SBATCH --time=00:06:00
#SBATCH --account=exaww


module --force purge 
export USERINSTALLATIONS=/p/usersoftware/slmet/easybuild/stages/2023/
module load Stages/2023 NVHPC/23.1 ParaStationMPI/5.8.0-1 netCDF-Fortran ecCodes libfyaml CMake
module list

#=============================================================================
set -x
ulimit -s unlimited
ulimit -c 0

#=============================================================================
#
# ICON run script:
# !ATTENTION! Do not change the format of the following lines.
#             They are evaluated by checksuite scripts.
# created by /p/home/jusers/duras1/juwels/duras1/icon-mpim_nextgems-BB-test/build_gpu.psmpi_nvhpc-23.1/run/make_target_runscript
# target machine is default
# target use_compiler is pgi
# with_mpi=yes
# with_openmp=no
# memory_model=large
# submit with 
#
builder=default_pgi
#=============================================================================
#
# OpenMP environment variables
# ----------------------------
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK:=1}
export ICON_THREADS=${OMP_NUM_THREADS}
export OMP_SCHEDULE=static
export OMP_DYNAMIC="false"
export OMP_STACKSIZE=200M
#
# MPI variables
# -------------
no_of_nodes=${SLURM_JOB_NUM_NODES:=1}
num_io_procs=4           # Note that it should match the number of atm output files
mpi_procs_pernode=${SLURM_TASKS_PER_NODE:=4}
((mpi_total_procs=no_of_nodes * mpi_procs_pernode))
#
# blocking length
# ---------------
nproma=1974
nproma_sub=1000
nblocks_c=0
proc0_shift=0

#
# Ecrad solver (0 for CPU/vector, 2 for GPU)
# ------------------------------------------
radiation_ecrad_isolver=0
#
#=============================================================================

# environment variables for the experiment and the target system
# --------------------------------------------------------------
export EXPNAME="NextGEMS_R2B4_test"

#=============================================================================
# directories with absolute paths
# -------------------------------
thisdir=$(pwd)
#export basedir="/p/home/jusers/duras1/juwels/duras1/icon-mpim_nextgems-BB-test/build_gpu.psmpi_nvhpc-23.1"
export basedir="$(realpath ${thisdir}/..)"
# experiments_dir can be predefined in a machine specific run_target_* header
experiments_dir="${experiments_dir:=${basedir}/experiments}"

# Where the output goes to
EXPDIR="${basedir}/experiments/${EXPNAME}"


# how to start the icon model
# ---------------------------
export START="srun --label -n $mpi_total_procs --cpu-bind none"
export MODEL="${basedir}/bin/icon"

set | grep SLURM

# how to submit the next job
# --------------------------
submit=""
job_name="exp.NextGEMS_R2B4_test.run"

# cdo for post-processing
# -----------------------
cdo="cdo"
cdo_diff="cdo diffn"

# define script functions used in the experiment run script
# ---------------------------------------------------------
. ${basedir}/run/add_run_routines

#=============================================================================

# ICON
#
# ------------------------------------------
# Copyright (C) 2004-2024, DWD, MPI-M, DKRZ, KIT, ETH, MeteoSwiss
# Contact information: icon-model.org
# See AUTHORS.TXT for a list of authors
# See LICENSES/ for license information
# SPDX-License-Identifier: BSD-3-Clause
# ------------------------------------------

# ----------------------------------------------------------------------------
# nextGEMS R2B4 atmosphere standalone - for testing only
# ----------------------------------------------------------------------------
#
author_list='Monika Esch, MPIM'
#--------------------------------------------------------------------------------------------------

# (1) Variables provided by the scripting mechanism

# EXPNAME                = name of exp. in 'exp.<name>'
# basedir                = base directory, where src/, run/ etc exist
# icon_data_poolFolder   = root directory for ICON data
# nproma                 = blocking length for array dimensioning and inner loop lengths
#                           which is set in run/create_target_header for the used machine
#
# nblocks_c              = number of looping chunks used for cells
#                          which is set in run/create_target_header for the used machine
#
# nproma_sub             = radiation blocking length
#                          which is set in run/create_target_header for the used machine
#
icon_data_poolFolder="/p/data1/slmet/model_data/ICON"


#--------------------------------------------------------------------------------------------------

# (2) Set variables needed by the scripting mechanism

# horizontal grid(s)
#
#
# domain globe
grid_id=0043
grid_id_land=0043-0036
grids_folder=${icon_data_poolFolder}/${grid_id}
grid_refinement=R02B04
grid_label=G
grid_name=icon_grid_${grid_id}_${grid_refinement}_${grid_label}
#
atmo_dyn_grids="'${grid_name}.nc'"

# start and end date+time
start_date=${start_date:="1979-01-01T00:00:00Z"}
    end_date=${end_date:="1979-01-01T00:36:00Z"}

# time steps
radTimeStep="PT2M"
atmTimeStep="PT2M"

# restart intervals
checkpoint_interval="P3D"
restart_interval="P3D"

# namelist files
atmo_namelist=NAMELIST_${EXPNAME}_atm
jsbach_namelist=NAMELIST_${EXPNAME}_lnd

#--------------------------------------------------------------------------------------------------

# (3) Define the model configuration

# JSBACH settings
jsbach_usecase=jsbach_lite    # jsbach_lite or jsbach_pfts
jsbach_with_carbon=no         # yes needs jsbach_pfts usecase

# Some further processing for land configuration
# ----------------------------------------------
#
lcarbon=$([ "${jsbach_with_carbon:=yes}" == yes ] && echo .TRUE. || echo .FALSE. )
#
if [[ $jsbach_usecase == *pfts* ]]
then
  pft_file_tag="11pfts_"
else
  pft_file_tag=""
fi

#--------------------------------------------------------------------------------------------------

# (6) Output control
# ------------------

# output intervals
# ---------------------

atm_output_interval_2d="PT6M"
atm_output_interval_3d="PT6M"
atm_file_interval="P1D"

# output file selection
# ---------------------

# output_<xyz>=yes : yes --> output files for <xyz>, any other value --> no files for <xyz>

output_atm_vgrid=no          # produces 1 file
output_atm_2d=yes            # produces 1 files
output_atm_3d=yes            # produces 3 files

# asynchronous diagnostic output processes
# ----------------------------------------

# Note that "mpi_atm_io_procs" should match the number of output files

mpi_atm_io_procs=${num_io_procs}          # total number of output files


# atmospheric dynamics and physics
# --------------------------------
#
# atmosphere namelist
# -------------------
cat > ${atmo_namelist} << EOF
&parallel_nml
 nproma               = ${nproma}
 nblocks_c            = ${nblocks_c}
 nproma_sub           = ${nproma_sub}
 num_io_procs         = ${mpi_atm_io_procs}
 io_proc_chunk_size   = 46
 io_process_stride    = 8
! num_restart_procs    = 0
/
&grid_nml
 dynamics_grid_filename = ${atmo_dyn_grids}
/
&run_nml
 num_lev              = 90          ! number of full levels
 modeltimestep        = "${atmTimeStep}"
 ltestcase            = .FALSE.     ! run testcase
 ldynamics            = .TRUE.      ! dynamics
 ltransport           = .TRUE.      ! transport
 iforcing             = 2           ! 0: none, 1: HS, 2: ECHAM, 3: NWP
 output               = 'nml'
 msg_level            = 12          ! level of details report during integration
 restart_filename     = "${EXPNAME}_restart_atm_<rsttime>.mfr"
 activate_sync_timers = .TRUE.
 profiling_output     = 1
 timers_level         = 10
/
&extpar_nml
 itopo                = 1           ! 1: read topography from the grid file
/
&initicon_nml
 init_mode            = 2           ! 2: initialize from IFS analysis
 ifs2icon_filename    = 'ifs2icon.nc'
 pinit_seed       = -1          ! seed for perturbation of initial model state. no perturbation by default
 pinit_amplitude  = 0.          ! amplitude of perturbation
/
&nonhydrostatic_nml
 damp_height          = 44000. ! [m]
 rayleigh_coeff       = 1      ! set to 0.1001 for rerun with little change
 vwind_offctr         = 0.2
 divdamp_fac          = 0.004
 divdamp_order        = 24
 divdamp_trans_end    = 17500
 divdamp_trans_start  = 12500
 divdamp_type         = 32
 exner_expol          = 0.333
 hbot_qvsubstep       = 16000.
 htop_moist_proc      = 22500.
 iadv_rhotheta        = 2
 igradp_method        = 3
 itime_scheme         = 4
 ivctype              = 2
 l_zdiffu_t           = .true.
 thhgtd_zdiffu        = 125.
 thslp_zdiffu         = 0.02
/
&interpol_nml
/
&sleve_nml
 min_lay_thckn        = 25.    ! [m]
 max_lay_thckn        = 400.   ! [m]
 top_height           = 75000. ! [m]
 stretch_fac          = 0.9
 decay_scale_1        = 4000.  ! [m]
 decay_scale_2        = 2500.  ! [m]
 decay_exp            = 1.2
 flat_height          = 16000. ! [m]
 htop_thcknlimit      = 14000.
/
&dynamics_nml
 lmoist_thdyn   = .TRUE.
/
&diffusion_nml
/
&transport_nml
 tracer_names         = 'hus','clw','cli','qr','qs','qg'
 ivadv_tracer         =    3 ,   3 ,   3 ,  3 ,  3 ,  3
 itype_hlimit         =    3 ,   4 ,   4 ,  4 ,  4 ,  4
 ihadv_tracer         =   20 ,  20 ,  20 , 20 , 20 , 20
/
&aes_phy_nml
!
! domain 1
! --------
!
! atmospheric physics (""=never)
 aes_phy_config(1)%dt_rad = "${radTimeStep}"
 aes_phy_config(1)%dt_vdf = "${atmTimeStep}"
 aes_phy_config(1)%dt_mig = "${atmTimeStep}"
!
! surface (.TRUE. or .FALSE.)
 aes_phy_config(1)%ljsb   = .TRUE.
 aes_phy_config(1)%lamip  = .TRUE.
 aes_phy_config(1)%lice   = .TRUE.
 aes_phy_config(1)%lmlo   = .FALSE.
 aes_phy_config(1)%llake  = .TRUE.

 aes_phy_config(1)%iqneg_d2p = 2
 aes_phy_config(1)%iqneg_p2d = 2
/
&aes_rad_nml
 aes_rad_config(1)%isolrad    = 1 ! Time dependent solar spectrum from file
 aes_rad_config(1)%irad_h2o   = 1
 aes_rad_config(1)%irad_co2   = 2
 aes_rad_config(1)%irad_ch4   = 12
 aes_rad_config(1)%irad_n2o   = 12
 aes_rad_config(1)%irad_o3    = 6 ! constant annual cycle climatology
 aes_rad_config(1)%irad_o2    = 2
 aes_rad_config(1)%irad_cfc11 = 2
 aes_rad_config(1)%irad_cfc12 = 2
 aes_rad_config(1)%irad_aero  = 12
 aes_rad_config(1)%vmr_co2    = 414.39e-06 ! constant ratio (348.0e-6)
 aes_rad_config(1)%vmr_ch4    = 1911.0e-09 ! constant ratio (1650.0e-9)
 aes_rad_config(1)%vmr_n2o    = 332.07e-09 ! constant ratio (306.0e-9)
 aes_rad_config(1)%lyr_perp   = .true.
 aes_rad_config(1)%yr_perp    = 2020
 aes_rad_config(1)%vmr_cfc11  = 218.23e-12
 aes_rad_config(1)%vmr_cfc12  = 495.02e-12
/
&aes_vdf_nml
 aes_vdf_config(1)%turb       = 2
 aes_vdf_config(1)%pr0        = 0.7
 aes_vdf_config(1)%use_tmx    = .TRUE. ! adapted to ngc3039, does not work proper yet
 aes_vdf_config(1)%energy_type        = 2   ! Only used for tmx
 aes_vdf_config(1)%dissipation_factor = 1.3 ! Only used for tmx
 aes_vdf_config(1)%louis_constant_b   = 4.2 ! default for R2B8
! aes_vdf_config(1)%lmix_max   = 150.
/
&aes_cov_nml
 aes_cov_config(1)%cqx  = 1.e-6
/
&aes_cop_nml
 aes_cop_config(1)%cinhomi  = 1.0
 aes_cop_config(1)%cinhoms  = 1.0
 aes_cop_config(1)%cinhoml  = 0.4
 aes_cop_config(1)%cn1lnd   = 50.0
 aes_cop_config(1)%cn1sea   = 50.0
 aes_cop_config(1)%cn2lnd   = 220.0
 aes_cop_config(1)%cn2sea   = 100.0
/
&cloud_mig_nml
/
&sea_ice_nml
 albedow_sim  = 0.10
 albi         = 0.70
 albim        = 0.65
 albs         = 0.80
 albsm        = 0.65
 i_ice_dyn    = 1
 i_ice_therm  = 1
 leadclose_1  = 0.25
 leadclose_2n = 0.666
/
EOF

# jsbach namelist
# ---------------

cat > ${jsbach_namelist} << EOF
&jsb_model_nml
 usecase             = "${jsbach_usecase}"
 use_lakes           = .TRUE.
 use_tmx             = .TRUE.    ! adapted to ngc3039, does not work proper yet
 fract_filename      = 'bc_land_frac.nc'
 init_from_ifs       = .TRUE.
/
&jsb_seb_nml
 bc_filename         = 'bc_land_phys.nc'
 ic_filename         = 'ic_land_soil.nc'
/
&jsb_rad_nml
 use_alb_veg_simple  = .TRUE.               ! Use TRUE for jsbach_lite, FALSE for jsbach_pfts
 bc_filename         = 'bc_land_phys.nc'
 ic_filename         = 'ic_land_soil.nc'
/
&jsb_turb_nml
 bc_filename         = 'bc_land_phys.nc'
 ic_filename         = 'ic_land_soil.nc'
 max_ini_rough_m     = 1.0 ! has to be set with tmx!
/
&jsb_sse_nml
 l_heat_cap_map      = .FALSE.
 l_heat_cond_map     = .FALSE.
 l_heat_cap_dyn      = .FALSE.
 l_heat_cond_dyn     = .FALSE.
 l_snow              = .TRUE.
 l_dynsnow           = .TRUE.
 l_freeze            = .TRUE.
 l_supercool         = .FALSE.
 bc_filename         = 'bc_land_soil.nc'
 ic_filename         = 'ic_land_soil.nc'
 l_soil_texture      = .FALSE.
/
&jsb_hydro_nml
 l_socmap            = .FALSE.
 l_organic           = .FALSE.
 bc_filename         = 'bc_land_soil.nc'
 ic_filename         = 'ic_land_soil.nc'
 bc_sso_filename     = 'bc_land_sso.nc'
! l_soil_texture      = .TRUE.
/
&jsb_assimi_nml
 active              = .FALSE.              ! Use FALSE for jsbach_lite, TRUE for jsbach_pfts
/
&jsb_pheno_nml
 scheme              = 'climatology'        ! scheme = logrop / climatology; use climatology for jsbach_lite
 bc_filename         = 'bc_land_phys.nc'
 ic_filename         = 'ic_land_soil.nc'
/
&jsb_carbon_nml
 active              = .FALSE.
 bc_filename         = 'bc_land_carbon.nc'
 ic_filename         = 'ic_land_carbon.nc'
 read_cpools         = .FALSE.
/
&jsb_fuel_nml
 active              = .FALSE.
 fuel_algorithm      = 1
/
&jsb_disturb_nml
 active              = .FALSE.
 ic_filename         = 'ic_land_soil.nc'
 bc_filename         = 'bc_land_phys.nc'
 fire_algorithm      = 1
 windbreak_algorithm = 1
 lburn_pasture       = .FALSE.
/
EOF

#--------------------------------------------------------------------------------------------------

# (4) Define the input

# model files
#
add_link_file ${basedir}/data/rrtmgp-gas-lw-g128.nc         ./coefficients_lw.nc
add_link_file ${basedir}/data/rrtmgp-gas-sw-g112.nc         ./coefficients_sw.nc
add_link_file ${basedir}/data/ECHAM6_CldOptProps_rrtmgp_lw.nc             ./rrtmgp-cloud-optics-coeffs-lw.nc
add_link_file ${basedir}/data/ECHAM6_CldOptProps_rrtmgp_sw.nc             ./rrtmgp-cloud-optics-coeffs-sw.nc

#
# namelist files
#
add_required_file ${basedir}/run/${atmo_namelist}                         ./
add_required_file ${basedir}/run/${jsbach_namelist}                       ./

# dictionary file for output variable names
#
dict_file="dict.${EXPNAME}"
cat dict.iconam.mpim  > ${dict_file}
add_required_file ${basedir}/run/${dict_file}                             ./

# initial and boundary conditions
# 
datadir=${icon_data_poolFolder}/${grid_id}/initial_condition/r0001
add_link_file $datadir/ifs2icon_1979010100_${grid_refinement}_G.nc        ./ifs2icon.nc
#
datadir=${icon_data_poolFolder}/${grid_id}/ozone/r0001
add_link_file $datadir/bc_ozone_picontrol.nc                              ./bc_ozone.nc
# 
datadir=${icon_data_poolFolder}/${grid_id}/sst_and_seaice/r0001
add_link_file $datadir/bc_sic_1979_2016.nc                                ./bc_sic.nc
add_link_file $datadir/bc_sst_1979_2016.nc                                ./bc_sst.nc
#
datadir=${icon_data_poolFolder}/${grid_id}/aerosol_kinne/r0001
add_link_file $datadir/bc_aeropt_kinne_lw_b16_coa.nc                      ./
add_link_file $datadir/bc_aeropt_kinne_sw_b14_coa.nc                      ./
add_link_file $datadir/bc_aeropt_kinne_sw_b14_fin_1850.nc                 ./bc_aeropt_kinne_sw_b14_fin.nc
#
datadir=${icon_data_poolFolder}/independent
add_link_file $datadir/greenhouse_gases/greenhouse_ssp245.nc              ./bc_greenhouse_gases.nc
#
datadir=${icon_data_poolFolder}/independent/solar_radiation/3.2
add_link_file $datadir/swflux_14band_cmip6_1850-2299-v3.2.nc              ./bc_solar_irradiance_sw_b14.nc
#
datadir=${icon_data_poolFolder}/${grid_id_land}/land/r0002
add_link_file $datadir/ic_land_soil_1979.nc                               ./ic_land_soil.nc
add_link_file $datadir/bc_land_frac_1979.nc                               ./bc_land_frac.nc
add_link_file $datadir/bc_land_phys_1979.nc                               ./bc_land_phys.nc
add_link_file $datadir/bc_land_soil_1979.nc                               ./bc_land_soil.nc
add_link_file $datadir/bc_land_sso_1979.nc                                ./bc_land_sso.nc
#
# - lctlib file for JSBACH
add_link_file ${basedir}/externals/jsbach/data/lctlib_nlct21.def          ./lctlib_nlct21.def
#-----------------------------------------------------------------------------
# Parameters for all output files
# -------------------------------
cat >> ${atmo_namelist} << EOF
&io_nml
 output_nml_dict      = "${dict_file}"
 netcdf_dict          = "${dict_file}"
 itype_pres_msl       = 4
 restart_file_type    = 5
 restart_write_mode   = 'joint procs multifile'
 lnetcdf_flt64_output = .TRUE.
/
EOF

# Define output files
# -------------------
#
# 3-dimensional files include 'ps' and 'pfull' to allow the vertical
# interpolation to pressure levels by cdo ap2pl.

# fixed model data only written at initial date
if [[ "$output_atm_vgrid" == "yes" ]]; then
  #
  cat >> ${atmo_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_vgrid"
 filename_format  = "<output_filename>_<levtype_l>"
 filetype         = 5
 remap            = 0
 output_grid      = .TRUE.
 output_start     = "${start_date}"             ! output_start = output_end
 output_end       = "${start_date}"             ! --> write once only irrespective of
 output_interval  = "${atm_output_interval_2d}" !     the output interval and
 file_interval    = "${atm_file_interval}"      !     the file interval
 ml_varlist       = 'zghalf'  , 'zg'      , 'dzghalf'
/
EOF
fi
#
#
if [[ "$output_atm_2d" == "yes" ]]; then
  #
  cat >> ${atmo_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_2d_ml"
 filename_format  = "<output_filename>_<datetime2>"
 filetype         = 5
 mode             = 1
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval_2d}" !
 file_interval    = "${atm_file_interval}"    !     the file interval
 operation        = 'mean'
 ml_varlist       = 'psl'     ,
                    'rsdt'    ,
                    'rsut'    , 'rsutcs'  , 'rlut'    , 'rlutcs'  ,
                    'rsds'    , 'rsdscs'  , 'rlds'    , 'rldscs'  ,
                    'rsus'    , 'rsuscs'  , 'rlus'    ,
                    'ts'      , 'clt'     ,
                    'pr'      , 'prw'     , 'cllvi'   , 'clivi'   ,
                    'hfls'    , 'hfss'    , 'evspsbl' ,
                    'tauu'    , 'tauv'    ,
                    'sfcwind' , 'tas'     ,
!                      ! Variables not used for quickplots, but for tables
                    'ps'      , 'cosmu0'  ,
                    'sic'     , 'sit'     ,
                    'albedo'  ,
                    'prlr'    , 'prls'    ,
                    'qgvi'    , 'qrvi'    , 'qsvi'    ,
                    'uas'     , 'vas'     , 'dew2'    ,
                    'cptgzvi' , 'duphyvi' , 'udynvi'  ,
                    'ufts'    , 'ufvs'    , 'ufcs'    ,
                    'rpds_dir', 'rpds_dif', 'rvds_dif', 'rnds_dif',
                    'pr_rain', 'pr_ice', 'pr_snow', 'pr_grpl',
/
EOF
fi
#
if [[ "$output_atm_3d" == "yes" ]]; then
  #
  cat >> ${atmo_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_1"
 filename_format  = "<output_filename>_<datetime2>"
 filetype         = 5
 mode             = 1
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 operation        = 'mean'
 output_interval  = "${atm_output_interval_3d}" !     the output interval and
 file_interval    = "${atm_file_interval}"    !     the file interval
 ml_varlist       = 'ta', 'ua', 'va',
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_2"
 filename_format  = "<output_filename>_<datetime2>"
 filetype         = 5
 mode             = 1
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 operation        = 'mean'
 output_interval  = "${atm_output_interval_3d}" !     the output interval and
 file_interval    = "${atm_file_interval}"    !     the file interval
 ml_varlist       = 'cl', 'cli', 'clw',
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_3"
 filename_format  = "<output_filename>_<datetime2>"
 filetype         = 5
 mode             = 1
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 operation        = 'mean'
 output_interval  = "${atm_output_interval_3d}" !     the output interval and
 file_interval    = "${atm_file_interval}"    !     the file interval
 ml_varlist       = 'wa', 'hus', 'pfull',
/
EOF
#
fi
#
#  get model
#
ls -l ${MODEL}
check_error $? "${MODEL} does not exist?"
#
ldd ${MODEL}
#
#-----------------------------------------------------------------------------
# ICON
#
# ---------------------------------------------------------------
# Copyright (C) 2004-2024, DWD, MPI-M, DKRZ, KIT, ETH, MeteoSwiss
# Contact information: icon-model.org
# See AUTHORS.TXT for a list of authors
# See LICENSES/ for license information
# SPDX-License-Identifier: BSD-3-Clause
# ---------------------------------------------------------------

#=============================================================================
#
# This section of the run script prepares and starts the model integration. 
#
# MODEL and START must be defined as environment variables or
# they must be substituted with appropriate values.
#
# Marco Giorgetta, MPI-M, 2010-04-21
#
#-----------------------------------------------------------------------------
final_status_file=${basedir}/run/${job_name}.final_status
rm -f ${final_status_file}
#-----------------------------------------------------------------------------
#
# directories definition
#
RUNSCRIPTDIR=${basedir}/run
if [ x$grids_folder = x ] ; then
   HGRIDDIR=${basedir}/grids
else
   HGRIDDIR=$grids_folder
fi

# make_and_change_to_experiment_dir
mkdir -p $EXPDIR
cd ${EXPDIR}

for dir in ${ADDITIONAL_SUBDIRS[@]}; do
  mkdir -p $dir
done

#-----------------------------------------------------------------------------
final_status_file=${RUNSCRIPTDIR}/${job_name}.final_status
rm -f ${final_status_file}

#-----------------------------------------------------------------------------
# set up the model lists if they do not exist
# this works for single model runs
# for coupled runs the lists should be declared explicilty
if [ x$namelist_list = x ]; then
#  minrank_list=(        0           )
#  maxrank_list=(     65535          )
#  incrank_list=(        1           )
  minrank_list[0]=0
  maxrank_list[0]=65535
  incrank_list[0]=1
  if [ x$atmo_namelist != x ]; then
    # this is the atmo model
    namelist_list[0]="$atmo_namelist"
    modelname_list[0]="atmo"
    modeltype_list[0]=1
    run_atmo="true"
  elif [ x$ocean_namelist != x ]; then
    # this is the ocean model
    namelist_list[0]="$ocean_namelist"
    modelname_list[0]="oce"
    modeltype_list[0]=2
  elif [ x$psrad_namelist != x ]; then
    # this is the psrad model
    namelist_list[0]="$psrad_namelist"
    modelname_list[0]="psrad"
    modeltype_list[0]=3
  elif [ x$hamocc_namelist != x ]; then
    # this is the hamocc model
    namelist_list[0]="$hamocc_namelist"
    modelname_list[0]="hamocc"
    modeltype_list[0]=4
  elif [ x$jsbach_namelist != x ]; then
    # this is the jsbach standalone model
    namelist_list[0]="$jsbach_namelist"
    modelname_list[0]="jsbach"
    modeltype_list[0]=5
    run_jsbach_standalone="true"
  elif [ x$testbed_namelist != x ]; then
    # this is the testbed model
    namelist_list[0]="$testbed_namelist"
    modelname_list[0]="testbed"
    modeltype_list[0]=99
  else
    check_error 1 "No namelist is defined"
  fi 
fi

#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# set some default values and derive some run parameteres
restart=${restart:=".false."}
restartSemaphoreFilename='isRestartRun.sem'
#AUTOMATIC_RESTART_SETUP:
if [ -f ${restartSemaphoreFilename} ]; then
  restart=.true.
  #  do not delete switch-file, to enable restart after unintended abort
  #[[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi
#END AUTOMATIC_RESTART_SETUP
#
# wait 5min to let GPFS finish the write operations
if [ "x$restart" != 'x.false.' -a "x$submit" != 'x' ]; then
  if [ x$(df -T ${EXPDIR} | cut -d ' ' -f 2) = gpfs ]; then
    sleep 10;
  fi
fi
# fill some checks

run_atmo=${run_atmo="false"}
if [ x$atmo_namelist != x ]; then
  run_atmo="true"
  run_jsbach_standalone="false"
fi
run_jsbach=${run_jsbach="false"}
if [ x$jsbach_namelist != x ]; then
  run_jsbach="true"
fi
run_ocean=${run_ocean="false"}
if [ x$ocean_namelist != x ]; then
  run_ocean="true"
fi
run_psrad=${run_psrad="false"}
if [ x$psrad_namelist != x ]; then
  run_psrad="true"
fi
run_hamocc=${run_hamocc="false"}
if [ x$hamocc_namelist != x ]; then
  run_hamocc="true"
fi

#-----------------------------------------------------------------------------
# add grids to required files
all_grids="${atmo_dyn_grids} ${atmo_rad_grids} ${ocean_grids}"
for gridfile in ${all_grids}; do
  #
  gridfile=${gridfile//\'/} # strip all ' in case ' is used to delimit the grid names
  gridfile=${gridfile//\"/} # strip all " in case " is used to delimit the grid names
  gridfile=${gridfile//\,/} # strip all , in case , is used to separate the grid names
  #
  grfinfofile=${gridfile%.nc}-grfinfo.nc
  #
  ls -l ${HGRIDDIR}/$gridfile
  check_error $? "${HGRIDDIR}/$gridfile does not exist."
  add_link_file ${HGRIDDIR}/${gridfile} ./
  if [ -f ${HGRIDDIR}/${grfinfofile} ]; then    
    add_link_file ${HGRIDDIR}/${grfinfofile} ./
  fi
done
#-----------------------------------------------------------------------------
# print_required_files
copy_required_files
link_required_files


#-----------------------------------------------------------------------------
# get restart files

if  [ x$restart_atmo_from != "x" ] ; then
  rm -f restart_atm_DOM01.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} ${EXPDIR}/restart_atm_DOM01.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} cp_restart_atm.nc
  ln -s cp_restart_atm.nc restart_atm_DOM01.nc
  restart=".true."
fi
if  [ x$restart_ocean_from != "x" ] ; then
  rm -f restart_oce.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} ${EXPDIR}/restart_oce.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} cp_restart_oce_DOM01.nc
  ln -s cp_restart_oce_DOM01.nc restart_oce_DOM01.nc
  restart=".true."
fi
#-----------------------------------------------------------------------------


read_restart_namelists=${read_restart_namelists:=".true."}

#-----------------------------------------------------------------------------
#
# create ICON master namelist
# ------------------------
# For a complete list see Namelist_overview and Namelist_overview.pdf

#-----------------------------------------------------------------------------
# create master_namelist
if [ -z "$dont_create_icon_master_namelist" ]; then
  master_namelist=icon_master.namelist

  calendar=${calendar:="proleptic gregorian"}
  calendar_type=${calendar_type:=1}
  {
    echo "&master_nml"
    echo " lrestart               =  $restart"
    echo " read_restart_namelists =  $read_restart_namelists"
    echo "/"

    if [ -z "$nsteps" ]; then
      echo "&master_time_control_nml"
      echo " calendar             = '$calendar'"
      echo " experimentStartDate  = '$start_date'"
      echo " restartTimeIntval    = '$restart_interval'"
      echo " checkpointTimeIntval = '$checkpoint_interval'"
      if [ -n "$end_date" ]; then
        echo " experimentStopDate = '$end_date'"
      fi
      echo "/"

      echo "&time_nml"
      echo " is_relative_time     = .false."
      echo "/"

    else # $nsteps is set -> use time_nml:ini_datetime_string
      echo "&time_nml"
      echo " calendar             =  $calendar_type"
      echo " ini_datetime_string  = '$start_date'"
      echo " dt_restart           =  $dt_restart"
      echo "/"
    fi
  } > $master_namelist

fi
#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# add model component to master_namelist
add_component_to_master_namelist()
{
  model_namelist_filename=$1
  if [ x${dont_create_icon_master_namelist+set} != xset ]; then
    model_name=$2
    model_type=$3
    model_min_rank=$4
    model_max_rank=$5
    model_inc_rank=$6
    model_rank_group_size=$7
    cat >> $master_namelist << EOF
&master_model_nml
  model_name="$model_name"
  model_namelist_filename="$model_namelist_filename"
  model_type=$model_type
  model_min_rank=$model_min_rank
  model_max_rank=$model_max_rank
  model_inc_rank=$model_inc_rank
  model_rank_group_size=$model_rank_group_size
/
EOF
  fi

  #-----------
  #get namelist
  if [ -f ${RUNSCRIPTDIR}/$model_namelist_filename ] ; then
    mv -f ${RUNSCRIPTDIR}/$model_namelist_filename ${EXPDIR}
    check_error $? "mv -f ${RUNSCRIPTDIR}/$model_namelist_filename ${EXPDIR}"
  else
    check_error 1 "${RUNSCRIPTDIR}/$model_namelist_filename does not exist"
  fi
}
#-----------------------------------------------------------------------------


no_of_models=${#namelist_list[*]}
echo "no_of_models=$no_of_models"

rank_group_size=1
j=0
while [ $j -lt ${no_of_models} ]
do
  add_component_to_master_namelist "${namelist_list[$j]}" "${modelname_list[$j]}" ${modeltype_list[$j]} ${minrank_list[$j]} ${maxrank_list[$j]} ${incrank_list[$j]} ${rank_group_size}
  j=`expr ${j} + 1`
done

#-----------------------------------------------------------------------------
# Add JSBACH part to master_namelist
# For several domains, $jsbach_namelist is only the basename for each domain's jsbach namelist;
#   the actual namelist files are appended by suffixes '_d1', '_d2', etc.

if [[ $run_jsbach == yes  ]] || [[ $run_jsbach == true ]]; then
  cat >> $master_namelist << EOF
&jsb_control_nml
 is_standalone      = .${run_jsbach_standalone:=false}.
 restart_jsbach     = ${restart}
 debug_level        = 0
 timer_level        = 0
/
EOF
#
if [[ -n ${atmo_dyn_grids} ]]; then
  no_of_domains=${#atmo_dyn_grids[@]}
else
  no_of_domains=1
fi
echo "no_of_domains=$no_of_domains"
domain=""
domain_suffix=""
j=1
while [ $j -le ${no_of_domains} ]
do
  if [[ $no_of_domains -gt 1 ]]; then
    # no_of_domains < 10 !
    domain=" DOM0${j}"
    domain_suffix="_d${j}"
  fi
  cat >> $master_namelist << EOF
&jsb_model_nml
 model_id = $j
 model_name = "JSBACH${domain}"
 model_shortname = "jsb${domain_suffix}"
 model_description = 'JSBACH land surface model'
 model_namelist_filename = "${jsbach_namelist}${domain_suffix}"
/
EOF
  if [[ ${run_jsbach_standalone} != true ]]; then
    if [[ -f ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} ]] ; then
      mv ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} ${EXPDIR}
      check_error $? "mv ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix}"
    else
      check_error 1 "${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} does not exist"
    fi
  fi
  j=`expr ${j} + 1`
done
fi

#
#  get model
#
ls -l ${MODEL}
check_error $? "${MODEL} does not exist?"
#
ldd ${MODEL}
#
#-----------------------------------------------------------------------------

#
# configure START_MODEL_function
#
# TODO: be less atmospheric centric, i.e. do not assume that atmosphere is always component 1
ICON_COMPONENT1_VH_procs=$(( ${num_restart_procs:-0} + ${num_io_procs:-0} + ${num_prefetch_proc:-0} + ${num_io_procs_radar:-0}))
ICON_COMPONENT2_VE_procs=0 # Note: probably one has to substrace $proc0_shift here if proc0_shift is used for the second component.
ICON_COMPONENT2_VH_procs=0 # TODO: use information about coupled processes to fill this

#
# start experiment
#

# Combine START and MODEL if START_MODEL is not already set.
# START_MODEL is used to ease the execution of a machine that uses a complex
# mpirun command with multiple binaries
START_MODEL="${START_MODEL:=$START $MODEL}"


rm -f finish.status
#
date
set -x
${START_MODEL} || exit 1
set +x
date
#
if [ -r finish.status ] ; then
  check_final_status 0 "${START} ${MODEL}"
else
  check_final_status -1 "${START} ${MODEL}"
fi
#
#-----------------------------------------------------------------------------
#
finish_status=`cat finish.status`
echo $finish_status
echo "============================"
echo "Script run successfully: $finish_status"
echo "============================"

#-----------------------------------------------------------------------------
# rm output_schedule_steps*
#-----------------------------------------------------------------------------
if [[ "x$use_hamocc" = "xyes" ]]; then
# store HAMOCC log file
strg="$(ls -rt ${EXPNAME}_hamocc_EU*.nc* | tail -1 )"
prefx="${EXPNAME}_hamocc_EU_tendencies"
foo=${strg##${prefx}}
foo=${foo%%.*}
bgcout_file="bgcout_${foo}"
mv bgcout $bgcout_file
fi
#-----------------------------------------------------------------------------
namelist_list=""
#-----------------------------------------------------------------------------
# check if we have to restart, ie resubmit
#   Note: this is a different mechanism from checking the restart
if [ $finish_status = "RESTART" ] ; then
  echo "restart next experiment..."
  this_script="${RUNSCRIPTDIR}/${job_name}"
  echo 'this_script: ' "$this_script"
  touch ${restartSemaphoreFilename}
  cd ${RUNSCRIPTDIR}
  ${submit} $this_script $run_param_0
else
  [[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi

#-----------------------------------------------------------------------------
# automatic call/submission of post processing if available
if [ "x${autoPostProcessing}" = "xtrue" ]; then
  # check if there is a postprocessing is available
  cd ${RUNSCRIPTDIR}
  targetPostProcessingScript="./post.${EXPNAME}.run"
  [[ -x $targetPostProcessingScript ]] && ${submit} ${targetPostProcessingScript}
  cd -
fi

#-----------------------------------------------------------------------------

cd $RUNSCRIPTDIR

#-----------------------------------------------------------------------------

	
# exit 0
#
# vim:ft=sh
#-----------------------------------------------------------------------------

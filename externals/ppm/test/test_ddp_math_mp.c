/**
 * @file test_ddp_math_mp.c
 * @brief test of PPM math extensions for multi-process double-double summation
 *
 * @copyright Copyright  (C)  2016-2017  Thomas Jahns <jahns@dkrz.de>
 *
 * @version 1.0
 * Keywords:
 * @author Thomas Jahns <jahns@dkrz.de>
 */
/*
 * Maintainer: Thomas Jahns <jahns@dkrz.de>
 * URL: https://www.dkrz.de/redmine/projects/scales-ppm
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are  permitted provided that the following conditions are
 * met:
 *
 * Redistributions of source code must retain the above copyright notice,
 * this list of conditions and the following disclaimer.
 *
 * Redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution.
 *
 * Neither the name of the DKRZ GmbH nor the names of its contributors
 * may be used to endorse or promote products derived from this software
 * without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER
 * OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include <inttypes.h>
#include <math.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>

#include <mpi.h>

#include <ppm/ppm.h>
#include <core/ppm_math_extensions.h>
#include <core/ppm_random.h>
#include <core/ppm_std_type_kinds_mp.h>

static double
naive_sum(size_t n, const double *restrict a);

int main(int argc, char **argv)
{
  MPI_Init(&argc, &argv);
  MPI_Comm comm = MPI_COMM_WORLD;
  int comm_rank, comm_size;
  MPI_Comm_rank(comm, &comm_rank);
  MPI_Comm_size(comm, &comm_size);
  unsigned seed;
  PPM_initialize(NULL, NULL, &seed);
  fprintf(stderr, "%d: seed=%u\n", comm_rank, seed);
  unsigned num_summands = 0;
  enum { min_summands=4096, max_summands = 1<<15 };
  /* enum { min_summands=16, max_summands = 32 }; */
  enum { block_size = 6 };
  bool debug = false;
  if (comm_rank == 0)
  {
    num_summands
      = (unsigned)((uint64_t)(PPM_ya_random()) * (max_summands - min_summands)
                   / UINT32_MAX) + min_summands;
    /* ensure num_summands is not a multiple of block-size */
    num_summands += (block_size - num_summands%block_size) % block_size;
    num_summands += PPM_ya_random()%(block_size - 1) + 1;
  }
  {
    unsigned t[2] = { seed, num_summands };
    MPI_Bcast(t, 2, MPI_UNSIGNED, 0, comm);
    seed = t[0];
    num_summands = t[1];
    seed = PPM_ya_rand_init(comm, (int)seed);
  }
  /* global offset into generated table of this task */
  size_t rank_ofs = (size_t)comm_rank * num_summands;
  /* global offset into generated table of this task, i.e. how many
   * blocks are generated by preceding ranks */
  size_t rank_initial_block = rank_ofs / block_size,
    initial_block_ofs = rank_ofs % block_size,
    full_block_roundup
    = (block_size - (num_summands + initial_block_ofs)%block_size)%block_size,
    alloc_num_summands = num_summands + initial_block_ofs + full_block_roundup,
    num_blocks = alloc_num_summands / block_size;
  /* let last task always finish summation on complete block */
  if (comm_rank == comm_size - 1)
  {
    num_summands += (unsigned)full_block_roundup + 1;
    ++alloc_num_summands;
  }
  double *summands = malloc(alloc_num_summands * sizeof (*summands));
  if (!summands)
    abort();
  /* draw as many random numbers as needed to pre-seed */
  for (size_t i = 0; i < rank_initial_block; ++i)
  {
    PPM_drandp();
    PPM_drandp();
    PPM_drandp();
  }
  for (size_t block_idx = 0; block_idx < num_blocks; ++block_idx)
  {
    double t1 = PPM_drandp(), t2 = PPM_drandp() * 0.5 + 0.5,
      t3 = PPM_drandp() * 0.5 + 0.5;
    double spacing_t1 = nextafter(t1, HUGE_VAL) - t1;
    if (fmod(t1, spacing_t1) != spacing_t1)
      t1 += spacing_t1;
    t1 = ldexp(t1, -53);
    t3 = ldexp(t3, -53);
    summands[block_idx * block_size + 0] = -t1;
    summands[block_idx * block_size + 1] =  t2;
    summands[block_idx * block_size + 2] =  t3;
    summands[block_idx * block_size + 3] = -t2;
    summands[block_idx * block_size + 4] = -t3;
    summands[block_idx * block_size + 5] =  t1;
  }
  double sum_ref;
  if (comm_rank == comm_size - 1)
    sum_ref
      = summands[num_blocks * block_size]
      = summands[num_blocks * block_size - 1];
  if (debug)
    for (int i = 0; i < comm_size; ++i)
    {
      if (i == comm_rank)
      {
        for (size_t i = 0; i < num_summands; ++i)
          fprintf(stderr, "[%4zu]=%.17g,\n",
                  rank_ofs + i, summands[initial_block_ofs + i]);
        fprintf(stderr, "%d: num_summands=%u, rank_initial_block=%zu,"
                " initial_block_ofs=%zu,\n"
                "%d: full_block_roundup=%zu, alloc_num_summands=%zu,\n"
                "%d: num_blocks=%zu, rank_ofs=%zu\n", comm_rank,
                num_summands, rank_initial_block, initial_block_ofs,
                comm_rank, full_block_roundup, alloc_num_summands,
                comm_rank, num_blocks, rank_ofs);
      }
      MPI_Barrier(comm);
    }
  /* compute local part ddp-corrected sum */
  double complex local_ddp_sum = PPM_ddp_sum_dp(num_summands,
                                                summands + initial_block_ofs);
  fprintf(stderr, "%d: local_ddp_sum=(%.17g, %.17g)\n",
          comm_rank, creal(local_ddp_sum), cimag(local_ddp_sum));
  double local_naive_sum = naive_sum(num_summands,
                                     summands + initial_block_ofs);
  fprintf(stderr, "%d: local_naive_sum=%.17g\n",
          comm_rank, local_naive_sum);
  double sum_naive;
  double complex sum_ddp;
  MPI_Reduce(&local_naive_sum, &sum_naive, 1, MPI_DOUBLE, MPI_SUM, 0, comm);
  if (comm_rank == 0)
    fprintf(stderr, "sum=%.17g\n", sum_naive);
  MPI_Reduce(&local_ddp_sum, &sum_ddp, 1, PPM_DT_C_DOUBLE_PAIR_MP,
             PPM_ddpdd_sum_op, 0, comm);
  MPI_Bcast(&sum_ref, 1, MPI_DOUBLE, comm_size - 1, comm);
  if (comm_rank == 0)
  {
    double tolerance = ldexp(sum_ref, -33),
      deviation_naive = fabs(sum_naive - sum_ref),
      deviation_ddp = fabs(creal(sum_ddp) - sum_ref);
    printf("reference          sum:          %.17g, tolerance: %.17g\n"
           "simple test, naive sum:          %.17g, deviation: %.17g\n"
           "simple test, DDP   sum:          %.17g, deviation: %.17g\n",
           sum_ref, tolerance,
           sum_naive, deviation_naive,
           creal(sum_ddp), deviation_ddp);
    if (deviation_naive <= tolerance)
      PPM_abort(comm, "Naive summation gave correct result, have you"
                " configured the FPU correctly?", __FILE__, __LINE__);
    if (deviation_ddp > tolerance)
      PPM_abort(comm, "Kahan summation failed, have you"
                " configured the FPU correctly?", __FILE__, __LINE__);
  }
  free(summands);
  PPM_finalize();
  MPI_Finalize();
  return EXIT_SUCCESS;
}

static double
naive_sum(size_t n, const double *restrict a)
{
  double s = 0.0;
  for (size_t i = 0; i < n; ++i)
    s += a[i];
  return s;
}


/*
 * Local Variables:
 * license-project-url: "https://www.dkrz.de/redmine/projects/scales-ppm"
 * license-markup: "doxygen"
 * license-default: "bsd"
 * End:
 */
